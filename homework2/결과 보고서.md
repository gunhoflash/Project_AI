# [2019-2 인공지능] 과제2 결과 보고서

2015920003 컴퓨터과학부 김건호



## 목차

1. 코드 설명
2. 실행 환경
3. 실행 결과
    1. 요약
    2. 실행 과정(input에 대한 그래프)
    3. 실행 과정(weight에 대한 그래프)
4. 분석
    1. AND-gate를 학습하지 못하는 특정조건
    2. XOR-gate를 학습하지 못하는 이유
    3. 효과적인 학습방법과 예시
5. 고찰: Error 분석과 학습속도



## 코드 설명

​	3개의 perceptron을 만들어 각각 AND-gate, OR-gate, XOR-gate의 동작을 하도록 학습시킨다.

​	main함수에서는 perceptron의 학습에 사용될 데이터를 정의하고 perceptron을 만들어 학습시킨다.

​	Perceptron.h 헤더파일에서 Perceptron을 class로 정의했으며 Calculate, Train 등 여러 메소드가 구현되어있다. Perceptron의 weight와 threshold는 contructor에서 아래 범위의 랜덤한 실수(float)로 초기화된다.

- weight: -1이상 1이하
- threshold: 0초과 1이하



> ### 필독
>
> ​	**[실행 결과]**의 내용은 모두 Learning Rate의 값을 `0.1`로 고정하고 진행한 것이다. 하지만 제출된 코드는 Learning Rate의 값이 `0.26`이고, 실행 결과 또한 *약간* 다르다. 그 이유는 **[분석] - [효과적인 학습방법과 예시]**에서 확인할 수 있다.



## 실행 환경

| 구분          | 값                        |
| ------------- | ------------------------- |
| 운영체제      | Windows 10 1903           |
| 빌드 도구     | Visual Studio 2019 (v142) |
| C++ 언어 표준 | C++14                     |



## 실행 결과

### 요약

![[그림 1] AND-gate 학습에 성공하는 모습](AND_Constant_Learning_Rate.png)

[그림 1] AND-gate 학습에 성공하는 모습



![[그림 2] OR-gate 학습에 성공하는 모습](OR_Constant_Learning_Rate.png)

[그림 2] OR-gate 학습에 성공하는 모습



![[그림 3] XOR-gate 학습에 실패하는 모습](XOR_Constant_Learning_Rate.png)

[그림 3] XOR-gate 학습에 실패하는 모습



![[그림 4] AND-gate 학습에 실패하는 모습](AND_Constant_Learning_Rate_Fail.png)

[그림 4] AND-gate 학습에 실패하는 모습



​	[그림 1], [그림 2]와 같이 AND-gate, OR-gate는 잘 학습하는 반면, [그림 3]과 같이 XOR-gate는 학습하지 못했다. 그리고 [그림 4]처럼 AND-gate 학습에 실패하는 경우도 가끔 발생했다.



### 실행 과정(input에 대한 그래프)

> - perceptron의 input을 각각 `x1`, `x2`라 한다.
> - 학습순서는 번호로 표시했고, 선의 색깔은 에러를 나타낸다.
>   - Error 0개: Black
>   - Error 1개: Blue
>   - Error 2개: Green
>   - Error 3개: Red
>   - Error 4개: 없음(threshold > 0 이므로 x1 = x2 = 0일때 반드시 Correct이다.)

![[그림 5] AND-gate 학습에 성공하는 과정](TR_AND.png)

[그림 5] AND-gate 학습에 성공하는 과정

- 초기값
  - weight: 0.748, -0.686
  - threshold: 0.253



![[그림 6] OR-gate 학습에 성공하는 과정](TR_OR.png)

[그림 6] OR-gate 학습에 성공하는 과정

- 초기값
  - weight: -0.438, 0.384
  - threshold: 0.641



![[그림 7] XOR-gate 학습에 실패하는 과정](TR_XOR.png)

[그림 7] XOR-gate 학습에 실패하는 과정

- 초기값
  - weight: 0.302, 0.958
  - threshold: 0.508



![[그림 8] AND-gate 학습에 실패하는 과정](TR_AND_fail.png)

[그림 8] AND-gate 학습에 실패하는 과정

- 초기값
  - weight: 0.496, 0.384
  - threshold: 0.064



### 실행 과정(weight에 대한 그래프)

> - perceptron의 weight를 각각 `w1`, `w2`라 한다.
> - 학습순서는 Start/(경로)/Finish로 표시했고, 점의 색깔은 에러를 나타낸다.
>   - Error 0개: Black
>   - Error 1개: Blue
>   - Error 2개: Green
>   - Error 3개: Red
>   - Error 4개: 없음(threshold > 0 이므로 x1 = x2 = 0일때 반드시 Correct이다.)
> - Error = 0을 만족하는 (w1, w2)의 영역을 회색으로 표시했다.

![[그림 9] AND-gate 학습에 성공하는 과정](TR_AND_W.png)

[그림 9] AND-gate 학습에 성공하는 과정

- 초기값
  - weight: 0.748, -0.686
  - threshold: 0.253



![[그림 10] OR-gate 학습에 성공하는 과정](TR_OR_W.png)

[그림 10] OR-gate 학습에 성공하는 과정

- 초기값
  - weight: -0.438, 0.384
  - threshold: 0.641



![[그림 11] XOR-gate 학습에 실패하는 과정](TR_XOR_W.png)

[그림 11] XOR-gate 학습에 실패하는 과정

- 초기값
  - weight: 0.302, 0.958
  - threshold: 0.508



![[그림 12] AND-gate 학습에 실패하는 과정](TR_AND_W_fail.png)

[그림 12] AND-gate 학습에 실패하는 과정

- 초기값
  - weight: 0.496, 0.384
  - threshold: 0.064



## 분석

### AND-gate를 학습하지 못하는 특정조건

​	[그림 4], [그림 8], [그림 12]는 AND-gate의 학습에 실패하는 과정을 보여준다. 이때 perceptron의 상태는 다음과 같다.

- Learning Rate: 0.1
- weight: 0.496, 0.384
- threshold: 0.064

​	[그림 12]에서 볼 수 있듯이, AND-gate를 만족하는 (w1, w2)의 영역이 매우 작다. 따라서 Learning Rate가 상대적으로 너무 커서 학습을 성공하지 못한다.



### XOR-gate를 학습하지 못하는 이유

​	[그림 3], [그림 7], [그림 11]은 XOR-gate의 학습에 실패하는 과정을 보여준다. 이때 perceptron의 상태는 다음과 같다.

- Learning Rate: 0.1
- weight: 0.302, 0.958
- threshold: 0.508

​	[그림 11]에는 회색 영역 대신 노란색 영역이 2개 있다. perceptron이 XOR-gate의 기능을 하려면 (w1, w2)가 이 두 곳에 모두 포함되어야 한다. 하지만 한 점이 두 영역에 포함되는 것은 불가능하므로 XOR-gate를 만족하는 (w1, w2)는 존재하지 않는다. [그림 7]을 보아도 선 하나로는 XOR-gate를 정의할 수 없음을 알 수 있다.



### 효과적인 학습방법과 예시

​	Perceptron의 학습과정에서 Weight 값이 조정될 때, Learning Rate가 너무 크면 원하는 목표에 정확히 도달하기 어렵다. 반대로 Learning Rate가 너무 작으면 학습에 굉장한 시간이 소요되므로 효율적이지 못하며, Error가 최소인 지점 대신 극소인 지점에 머무르게 될 수도 있다. 따라서 Learning Rate를 **적당히** 설정하는 것이 학습에 매우 중요하다.

​	물론, 랜덤하게 설정되는 Threshold의 범위를 다르게 조정하는 방법도 학습과정에 영향을 준다. 앞서 본 AND-gate 학습 실패 사례는 Threshold가 너무 작은 값(`0.064`)을 가진 것에서 기인되었으므로, 랜덤하게 설정되는 Threshold의 최소값을 더 높였다면 학습에 성공했을 수 있다. 하지만 여전히 Learning Rate와의 상대적인 크기에 따라 Threshold의 최소값 조정은 무의미할 수도 있다. 즉, Threshold와 Learning Rate가 **서로 적당히** 설정되어야 한다.

​	나는 편의를 위해 Threshold의 범위를 여전히 0과 1 사이로 제한하고, 이에 적당하게 Learning Rate를 맞추기로 했다. 그리고 **적당한** Learning Rate를 설정하기 위해서 **동적인 Learning Rate**를 적용했다. 그 방법은 다음과 같다.

> #### Dynamic Learning Rate
>
> ​	학습 초기에는 Error가 적은 방향으로 weight를 충분히 조정해야 하므로 Learning Rate를 크게 설정한다. 이후 학습을 진행하다가 원하는 목표를 달성하기 어려운 상태가 되었을 때(아직 Error가 큰데도 Weight 값이 변하지 않거나 진동할 때), Learning Rate의 크기를 절반으로 줄이고 다시 학습을 진행한다. Error가 충분히 작아지거나 더이상 Learning Rate의 값을 줄일 수 없을 때까지(디지털 숫자를 계속 줄이다보면 결국 0이 되기 때문) 이 과정을 반복한다.

​	이렇게 함으로써 Weight를 더 세밀하게 조정할 수 있고, Perceptron의 Error를 조금 더 낮출 것이라 기대할 수 있다. 물론, 이 학습방법을 적용해도 Weight 값들이 Error가 최소가 아닌 극소인 지점으로 수렴할 가능성은 여전히 배제할수 없지만, Constant Learning Rate 방식에 비해 Error를 최소화 할 것이라 기대할 수 있다.



 	앞서 AND-gate 학습에 실패했던 사례에 Dynamic Learning Rate 방식을 적용하면 다음과 같이 학습이 진행된다.

![[그림 13] Dynamic Learning Rate를 적용한 AND-gate 학습과정](AND_Dynamic_Learning_Rate.png)

[그림 13] Dynamic Learning Rate를 적용한 AND-gate 학습과정



![[그림 14] Dynamic Learning Rate를 적용한 AND-gate 학습과정](TR_AND_D.png)

[그림 14] Dynamic Learning Rate를 적용한 AND-gate 학습과정



![[그림 15] Dynamic Learning Rate를 적용한 AND-gate 학습과정](TR_AND_W_D.png)

[그림 15] Dynamic Learning Rate를 적용한 AND-gate 학습과정



​	[그림 16]은 Learning Rate의 초기값을 `0.26`으로 증가시켰을 때의 학습과정이다. 이 예시처럼, Dynamic Learning Rate를 적용하고 Learning Rate의 초기값을 크게 하면 학습과정을 단축시킬 수 있다. (별도의 그래프는 생략함)

![[그림 16] Dynamic Learning Rate(0.26)를 적용한 AND-gate 학습과정](AND_Dynamic_Learning_Rate_0.26.png)

[그림 16] Dynamic Learning Rate(0.26)를 적용한 AND-gate 학습과정



> ### 필독
>
> ​	위와 같은 이유에 따라, 제출된 코드에는 Learning Rate의 초기값이 `0.26`인 Dynamic Learning Rate를 적용하였다. 하지만, 여전히 Constant Learning Rate를 적용하기 쉽도록 주석을 달아두었다. Perceptron::Train 메소드에서 `// continue;`부분의 주석을 해제하면 Constant Learning Rate가 적용된다.



## 고찰: Error 분석과 학습속도

​	이 코드는 current weight에 대한 training dataset에서의 error의 수를 정확히 파악하기 위해, 학습 과정에서 Calculate 함수를 두 번씩 호출한다. 첫 Calculate는 Weight 재조정을 위한 것이고, 그 다음 Calculate는 재조정된 Weight에 대한 Error 계산을 위한 것이다. 이하는 이와 다른 학습방법에 대한 내용이다.



​	하나의 Training Data에 대한 Calculate마다 Weight를 재조정함과 동시에 Error를 세는 방법을 생각해보자. 이 방법을 내 코드에 적용하면 Perceptron::Train 메소드의 내용은 다음과 같을 것이다.

```c++
// ...
while (trainable)
{
    printf("[Round %03d]\t", round++);

    // save current weight values
    SaveWeights();

    // calculate, feedback, and count the number of errors
    error = CalculateTrainingDataset(length, inputs, outputs, true);

    // print readjusted weight values
    PrintWeights();
    
    // 여기서 Error를 따로 세지 않는다!

    // print the number of errors
    printf("\tError: %d\n", error);

    // ...
}
// ...
```

​	이 방법은 뚜렷한 장단점이 있다.

​	단점은, 이렇게 계산한 error의 값이 정확하지 않다는 것이다. 한 Round의 학습을 진행하고 얻은 Error의 합은 특정 Weight에 대한 것이 아니다. Error를 세면서 동시에 Weight값도 변해왔기 때문이다. 여기서 얻어지는 Error의 합은 단순히 전체 학습과정에서의 대략적인 Error 변화(또는 Weight의 재조정 횟수)의 흐름만을 나타낼 뿐, 크게 신뢰할만한 수치는 아니다. 따라서 이것은 학습과정에서 Error의 변화를 정확하게 파악할 목적에는 부적합한 방법이다.

​	장점은, Error의 변화에 관심이 없고 단지 빠른 학습만을 원한다면 이 방법이 꽤 매력적이라는 것이다. 비록 학습과정에서 필요한 Round의 수는 변화가 없지만, Calculate를 한 번씩만 호출하므로 전체적인 소요시간은 단축된다. 그러면서도, 이 방법에서 Error가 0이 될 때는 Weight의 재조정이 단 한 번도 없었다는 뜻이므로 학습완료를 보장할 수 있다.

